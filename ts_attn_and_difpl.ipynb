{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"device:\", device)\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/世界モデル_最終課題/timeseries.csv\")\n",
        "\n",
        "ID_COL = \"patient_id\"\n",
        "TIME_COL = \"time_days\"\n",
        "\n",
        "feature_cols = [\n",
        "    c for c in df.columns\n",
        "    if c not in [ID_COL, TIME_COL]\n",
        "    and not c.startswith(\"met_\")\n",
        "    and not c.startswith(\"tx_\")\n",
        "]\n",
        "\n",
        "F = len(feature_cols)\n",
        "print(\"num features:\", F)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
        "\n",
        "def make_triples(df):\n",
        "    \"\"\"\n",
        "    (x_t, x_{t+1}) でグラフを作って x_{t+2} を予測するためのサンプルを作る\n",
        "    \"\"\"\n",
        "    triples = []\n",
        "    for pid, g in df.groupby(ID_COL):\n",
        "        g = g.sort_values(TIME_COL)\n",
        "        x = g[feature_cols].values\n",
        "        t = g[TIME_COL].values\n",
        "\n",
        "        # t, t+1, t+2 が必要なので -2 まで\n",
        "        for i in range(len(g) - 2):\n",
        "            triples.append({\n",
        "                \"pid\": pid,\n",
        "                \"x_t\": x[i],\n",
        "                \"x_tp1\": x[i+1],\n",
        "                \"x_tp2\": x[i+2],\n",
        "                \"dt01\": float(t[i+1] - t[i]),\n",
        "                \"dt12\": float(t[i+2] - t[i+1]),\n",
        "            })\n",
        "    return triples\n",
        "\n",
        "triples = make_triples(df)\n",
        "print(\"num triples:\", len(triples))\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as torch_F\n",
        "\n",
        "class CrossTimeAttention(nn.Module):\n",
        "    def __init__(self, in_dim, attn_dim):\n",
        "        super().__init__()\n",
        "        self.q = nn.Linear(in_dim, attn_dim, bias=False)\n",
        "        self.k = nn.Linear(in_dim, attn_dim, bias=False)\n",
        "\n",
        "    def forward(self, x_t, x_tp1):\n",
        "        \"\"\"\n",
        "        x_t, x_tp1: (F, in_dim)\n",
        "        \"\"\"\n",
        "        Q = self.q(x_t)\n",
        "        K = self.k(x_tp1)\n",
        "        A = Q @ K.T / np.sqrt(Q.size(-1))\n",
        "        return torch_F.softmax(A, dim=1)  # row-wise\n",
        "\n",
        "!pip -q install torch-geometric\n",
        "\n",
        "from torch_geometric.nn import GCNConv, dense_diff_pool\n",
        "\n",
        "class DiffPoolItemNet(nn.Module):\n",
        "    def __init__(self, in_dim, hidden_dim, num_clusters):\n",
        "        super().__init__()\n",
        "        self.gnn_embed = GCNConv(in_dim, hidden_dim)\n",
        "        self.gnn_pool  = GCNConv(in_dim, num_clusters)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # dense adj -> edge_index/edge_weight\n",
        "        edge_index = adj.nonzero().T\n",
        "        edge_weight = adj[edge_index[0], edge_index[1]]\n",
        "\n",
        "        z = self.gnn_embed(x, edge_index, edge_weight)\n",
        "        s = self.gnn_pool(x, edge_index, edge_weight)\n",
        "\n",
        "        x_pool, adj_pool, _, _ = dense_diff_pool(\n",
        "            z.unsqueeze(0),\n",
        "            adj.unsqueeze(0),\n",
        "            s.unsqueeze(0)\n",
        "        )\n",
        "        return x_pool.squeeze(0), adj_pool.squeeze(0), s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSd1TyiOvgb2",
        "outputId": "4abf062d-d280-47ef-dfd7-aa2f0d04179c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device: cuda\n",
            "num features: 42\n",
            "num triples: 123742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ItemGraphEncoder(nn.Module):\n",
        "    def __init__(self, num_clusters, F_features):\n",
        "        super().__init__()\n",
        "        self.F_features = F_features\n",
        "        self.attn = CrossTimeAttention(1, 16)\n",
        "        self.diffpool = DiffPoolItemNet(4, 16, num_clusters) # Reduced hidden_dim from 32 to 16\n",
        "        self.latent_dim = num_clusters * 16   # Adjusted latent_dim accordingly\n",
        "\n",
        "    def forward(self, triple):\n",
        "        x_t   = torch.tensor(triple[\"x_t\"],   dtype=torch.float, device=device)\n",
        "        x_tp1 = torch.tensor(triple[\"x_tp1\"], dtype=torch.float, device=device)\n",
        "        dt01  = torch.tensor(triple[\"dt01\"],  dtype=torch.float, device=device)\n",
        "\n",
        "        A = self.attn(x_t.unsqueeze(1), x_tp1.unsqueeze(1))\n",
        "\n",
        "        H = torch.stack([\n",
        "            x_t,\n",
        "            x_tp1,\n",
        "            x_tp1 - x_t,\n",
        "            torch.ones(self.F_features, device=device) * dt01,\n",
        "        ], dim=1)\n",
        "\n",
        "        x_pool, _, S = self.diffpool(H, A)\n",
        "        z = x_pool.flatten()   # ← ここが GRU に入る\n",
        "        return z, S"
      ],
      "metadata": {
        "id": "THuYdFgMQRI_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatientGRUModel(nn.Module):\n",
        "    def __init__(self, latent_dim, F):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=latent_dim,\n",
        "            hidden_size=128,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.decoder = nn.Linear(128, F)\n",
        "\n",
        "    def forward(self, z_seq):\n",
        "        # z_seq: (1, T-2, latent_dim)\n",
        "        out, _ = self.gru(z_seq)\n",
        "        h_last = out[:, -1]\n",
        "        return self.decoder(h_last).squeeze(0)\n"
      ],
      "metadata": {
        "id": "kKFiGMMhQTD5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "triples_by_pid = defaultdict(list)\n",
        "for tr in triples:\n",
        "    triples_by_pid[tr[\"pid\"]].append(tr)"
      ],
      "metadata": {
        "id": "SobbjCJeQUhH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = ItemGraphEncoder(num_clusters=3, F_features=F).to(device) # Reduced num_clusters from 5 to 3\n",
        "gru_model = PatientGRUModel(\n",
        "    latent_dim=encoder.latent_dim,\n",
        "    F=F\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(\n",
        "    list(encoder.parameters()) + list(gru_model.parameters()),\n",
        "    lr=1e-3\n",
        ")\n"
      ],
      "metadata": {
        "id": "3x_EVEAOQV6J"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    encoder.train()\n",
        "    gru_model.train()\n",
        "\n",
        "    total_epoch_loss = 0.0\n",
        "    n_pred_epoch = 0\n",
        "\n",
        "    for pid, patient_triples in triples_by_pid.items():\n",
        "        if len(patient_triples) < 2:\n",
        "            continue\n",
        "\n",
        "        # --- 1. 全時点の z を計算 ---\n",
        "        z_list = []\n",
        "        for tr in patient_triples:\n",
        "            z, _ = encoder(tr)\n",
        "            z_list.append(z)\n",
        "\n",
        "        z_seq = torch.stack(z_list).unsqueeze(0)  # (1, T, D)\n",
        "\n",
        "        patient_loss = 0.0  # Accumulate loss per patient\n",
        "        n_pred_patient = 0\n",
        "\n",
        "        # --- 2. 各時点で予測 & loss ---\n",
        "        for t in range(len(patient_triples)):\n",
        "            if t == 0:\n",
        "                continue  # GRUは最低1ステップ必要\n",
        "\n",
        "            pred = gru_model(z_seq[:, :t+1])   # 過去→現在\n",
        "            target = torch.tensor(\n",
        "                patient_triples[t][\"x_tp2\"],\n",
        "                dtype=torch.float,\n",
        "                device=device\n",
        "            )\n",
        "\n",
        "            loss = torch_F.mse_loss(pred, target)\n",
        "            patient_loss += loss\n",
        "            n_pred_patient += 1\n",
        "\n",
        "        if n_pred_patient > 0:\n",
        "            patient_loss = patient_loss / n_pred_patient\n",
        "\n",
        "            # Backpropagate and update weights for this patient\n",
        "            optimizer.zero_grad()\n",
        "            patient_loss.backward()  # Backpropagate patient_loss\n",
        "            optimizer.step()\n",
        "\n",
        "            total_epoch_loss += patient_loss.item() * n_pred_patient # Accumulate detached loss for epoch display\n",
        "            n_pred_epoch += n_pred_patient\n",
        "\n",
        "    if n_pred_epoch > 0:\n",
        "        avg_epoch_loss = total_epoch_loss / n_pred_epoch\n",
        "    else:\n",
        "        avg_epoch_loss = 0.0\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        print(f\"epoch {epoch}: loss={avg_epoch_loss:.4f}\")"
      ],
      "metadata": {
        "id": "J5y5dXWAQXtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "with torch.no_grad():\n",
        "    _, S = encoder(patient_triples[0])\n",
        "\n",
        "S = S.softmax(dim=1).cpu().numpy()\n"
      ],
      "metadata": {
        "id": "bMJJlP8GQZW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, max(4, F*0.15)))\n",
        "sns.heatmap(\n",
        "    S, cmap=\"viridis\",\n",
        "    yticklabels=feature_cols,\n",
        "    xticklabels=[f\"C{k}\" for k in range(S.shape[1])]\n",
        ")\n",
        "plt.title(\"Item → Cluster Assignment (from x_t, x_{t+1})\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rc708_3nQyJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qAAi1KxTQycu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}